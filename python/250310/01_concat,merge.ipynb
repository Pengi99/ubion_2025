{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터프레임의 결합\n",
    "- 유니언 결합 \n",
    "    - 단순하게 행이나 열을 결합하는 방식 \n",
    "    - pandas에 내장된 concat() 함수를 이용  \n",
    "        - concat( [ 데이터프레임명, 데이터프레임명, ... ] )\n",
    "            - axis 매개변수\n",
    "                - 0(rows) : 행을 결합 \n",
    "                - 1(columns) : 열을 결합\n",
    "            - ignore_index 매개변수\n",
    "                - False(기본값) : 결합되는 인덱스를 보존\n",
    "                - True : 결합되는 인덱스를 초기화\n",
    "- 조인 결합\n",
    "    - 특정한 조건에 맞춰서 열을 결합 \n",
    "    - 데이터프레임과 데이터프레임 간의 조인결합 -> 특정 컬럼의 데이터들이 같은 값들로 이루어져 있는 경우에만 열을 추가하는 결합\n",
    "    - pandas에 내장된 merge() 함수를 이용\n",
    "        - merge( 데이터프레임명, 데이터프레임명 )\n",
    "            - on 매개변수 \n",
    "                - 조건식 (두 개의 데이터프레임이 공통적으로 가지고 있는 컬럼의 이름)\n",
    "                - 두 데이터프레임에서 기준이 되는 컬럼의 이름이 다른 경우 \n",
    "                    - 데이터프레임의 컬럼의 이름을 변경하고 결합 \n",
    "                    - left_on, right_on 매개변수를 이용하여 컬럼의 이름을 지정 \n",
    "            - how 매개변수 \n",
    "                - 조인결합의 방법을 지정 \n",
    "                    - inner : 두 개의 데이터프레임이 공통적으로 가지고 있는 데이터만 결합해서 출력 \n",
    "                    - left : 왼쪽의 데이터프레임을 기준으로 결합 \n",
    "                    - right : 오른쪽의 데이터프레임을 기준으로 결합 \n",
    "                    - outer : 두 개의 데이터프레임의 합집합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\" : ['test', 'test2', 'test3'], \n",
    "    'age' : [20, 30, 40]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = {\n",
    "    'name' : ['test4', 'test5'], \n",
    "    'loc' : ['seoul', 'busan']\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat() : 행 결합\n",
    "pd.concat( [df, df2] , axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat( [df, df2] ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat( [df, df2] ).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat() : 열 결합\n",
    "pd.concat( [df, df2], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = {\n",
    "    'name' : ['test6', 'test7'],\n",
    "    'age' : [25, 35]\n",
    "}\n",
    "df3 = pd.DataFrame(data3)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat( [df, df2, df3] , axis=0 , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat( [df, df2, df3], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.rename(\n",
    "    index={\n",
    "        0 : 10, \n",
    "        1 : 15\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.index = [10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df, df2, df3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat 함수는 pandas에만 존재\n",
    "# df.concat( [df2, df3], axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'name' : ['test', 'test2', 'test4'], \n",
    "    'loc' : ['서울', '경기', '대구']\n",
    "}\n",
    "df4 = pd.DataFrame(data)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, df4, on='name', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, df4, on='name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, df4, on='name', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df, df4, on='name', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'location' : ['서울', '경기', '대구', '세종'], \n",
    "    'code' : ['11', '31', '32', '41']\n",
    "}\n",
    "df5 = pd.DataFrame(data)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4, df5 조인결합 \n",
    "# 기준의 되는 컬럼의 이름이 다른 경우\n",
    "pd.merge(df4, df5, left_on='loc', right_on='location', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 데이터프레임중 하나의 컬럼의 이름을 변경하고 조인결합\n",
    "df5.rename(\n",
    "    columns = {\n",
    "        'location' : 'loc'\n",
    "    }, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df4, df5, on='loc', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.merge(df5, on='loc', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터프레임 결합 예제\n",
    "1. csv 폴더 안에 있는 tran_1, tran_2, tran_d_1, tran_d_2 파일을 로드 \n",
    "2. tran_1, tran_2를 단순 행 결합 \n",
    "3. tran_d_1, tran_d_2를 단순 행 결합 \n",
    "4. 2번의 결과와 3번의 결과를 조인 결합(inner) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_1 = pd.read_csv(\"../../csv/tran_1.csv\")\n",
    "tran_2 = pd.read_csv(\"../../csv/tran_2.csv\")\n",
    "tran_d1 = pd.read_csv(\"../../csv/tran_d_1.csv\")\n",
    "tran_d2 = pd.read_csv(\"../../csv/tran_d_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tran_1, tran_2 단순한 행 결합 \n",
    "tran = pd.concat( [tran_1, tran_2], axis=0, ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tran_d1, tran_d2 단순한 행 결합 \n",
    "print(len(tran_d1))\n",
    "print(len(tran_d2))\n",
    "tran_d = pd.concat( [tran_d1, tran_d2] , axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_d.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(tran, tran_d, how='left', on='transaction_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_mater 파일 로드 \n",
    "item_master = pd.read_csv(\"../../csv/item_master.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_d.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df와 item_master를 조인 결합 \n",
    "total_df = df.merge(item_master, on = 'item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction_id가 2개 이상인 데이터들만 출력 \n",
    "# 중복데이터가 존재하는가?\n",
    "# 값들의 카운터를 확인하는 함수 \n",
    "df2 = total_df['transaction_id'].value_counts()\n",
    "id_list2 = df2[df2 > 1].index\n",
    "len(id_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스를 이동하는 함수 shift()\n",
    "flag = \\\n",
    "    total_df['transaction_id'] == total_df.shift()['transaction_id']\n",
    "id_list = total_df.loc[flag, 'transaction_id']\n",
    "len(id_list.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_df의 인덱스를 transaction_id 변경\n",
    "# set_index('컬럼명')\n",
    "total_df.set_index('transaction_id')\\\n",
    "    .loc[id_list2].reset_index()\\\n",
    "        [ ['transaction_id', \"price\", \"item_price\", \"quantity\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicated() : 중복 데이터를 체크하는 함수 \n",
    "# subset 매개변수 : 어떤 열의 데이터의 중복을 체크할것인가? (기본값은 모든 열)\n",
    "# keep : \n",
    "#   'first' : 중복되는 데이터중 첫번째 데이터는 False\n",
    "#   'last' : 중복되는 데이터 중 마지막 데이터는 False\n",
    "#   False : 중복되는 데이터 모두 True\n",
    "flag = total_df.duplicated(subset='transaction_id', keep=False)\n",
    "total_df.loc[flag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.duplicated(subset='transaction_id', keep=False).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'id' : ['a', 'b', 'c', 'd', 'd'], \n",
    "    'pass' : ['1111', '1234', '2222', '0000', '0001']\n",
    "}\n",
    "test_df = pd.DataFrame(data)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.duplicated(subset='id', keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 데이터를 제거하는 함수수\n",
    "test_df.drop_duplicates(subset='id', keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떤 요일에 매출이 가장 높은가?\n",
    "# payment_date를 시계열 데이터로 변경 \n",
    "total_df['payment_date'] = \\\n",
    "    pd.to_datetime(total_df['payment_date'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "# 요일 컬럼을 생성해서 시계열 데이터에서 요일(축약된 이름)을 추출하여 대입\n",
    "# case1 (map함수 이용)\n",
    "# total_df['payment_date'].map(\n",
    "#     lambda x : x.strftime('%a')\n",
    "# )\n",
    "# Series에서 datetime 함수를 이용\n",
    "total_df['요일'] = total_df['payment_date'].dt.strftime('%a')\n",
    "# price2 컬럼을 생성 item_price * quantity 결과를 대입\n",
    "total_df['price2'] = total_df['item_price'] * total_df['quantity']\n",
    "# 요일별로 그룹화하여 price2의 합산\n",
    "group_data = total_df[ [ 'price2', '요일' ] ].groupby('요일').sum()\n",
    "# price2를 기준으로 내림차순 정렬\n",
    "group_data.sort_values('price2', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복된 데이터를 첫번째 한개를 남겨두고 모두 제거 \n",
    "total_df2 = total_df.drop_duplicates(subset='transaction_id', keep='first')\n",
    "print(len(total_df2))\n",
    "total_df2[['요일', 'price']].groupby('요일').sum().sort_values('price', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>요일</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fri</th>\n",
       "      <td>1008</td>\n",
       "      <td>143422.619048</td>\n",
       "      <td>144570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mon</th>\n",
       "      <td>941</td>\n",
       "      <td>139606.801275</td>\n",
       "      <td>131370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sat</th>\n",
       "      <td>975</td>\n",
       "      <td>144230.769231</td>\n",
       "      <td>140625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sun</th>\n",
       "      <td>994</td>\n",
       "      <td>141634.808853</td>\n",
       "      <td>140785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thu</th>\n",
       "      <td>929</td>\n",
       "      <td>147168.998924</td>\n",
       "      <td>136720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tue</th>\n",
       "      <td>961</td>\n",
       "      <td>143595.213319</td>\n",
       "      <td>137995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wed</th>\n",
       "      <td>978</td>\n",
       "      <td>142198.364008</td>\n",
       "      <td>139070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price                          \n",
       "    count           mean        sum\n",
       "요일                                 \n",
       "Fri  1008  143422.619048  144570000\n",
       "Mon   941  139606.801275  131370000\n",
       "Sat   975  144230.769231  140625000\n",
       "Sun   994  141634.808853  140785000\n",
       "Thu   929  147168.998924  136720000\n",
       "Tue   961  143595.213319  137995000\n",
       "Wed   978  142198.364008  139070000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df2[['요일', 'price']].groupby('요일').agg(['count','mean', 'sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 특정 경로 상에 있는 파일들을 로드 \n",
    "- 일반적인 방법 : 상대경로, 절대경로를 이용해서 각각의 파일들을 로드 \n",
    "- 특정 경로에 존재하는 파일의 리스트 출력 \n",
    "    - os 라이브러리 사용\n",
    "    - glob 라이브러리 사용\n",
    "- 반복문을 이용하여 파일들을 모두 로드 \n",
    "    - 반복을 통해서 데이터프레임을 모두 행 결합\n",
    "    - 반복을 통해서 데이터프레임을 각각 다른 변수에 대입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['201701_expense_list.csv',\n",
       " '201702_expense_list.csv',\n",
       " '201703_expense_list.csv',\n",
       " '201704_expense_list.csv',\n",
       " '201705_expense_list.csv',\n",
       " '201706_expense_list.csv',\n",
       " '201707_expense_list.csv',\n",
       " '201708_expense_list.csv',\n",
       " '201709_expense_list.csv',\n",
       " '201710_expense_list.csv',\n",
       " '201711_expense_list.csv',\n",
       " '201712_expense_list.csv']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os 라이브러리 안에 listdir() 사용 \n",
    "os.listdir(\"../../csv/2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 경로를 변수에 저장 \n",
    "file_path = \"../../csv/2017\"\n",
    "# 특정 경로의 파일의 목록\n",
    "file_list = os.listdir(file_path)\n",
    "\n",
    "# 반복문을 통해 로드가되는 데이터프레임을 결합하는 빈 데이터프레임을 생성\n",
    "df_2017 = pd.DataFrame()\n",
    "# 반복문을 이용\n",
    "for file_name in file_list:\n",
    "    # pandas 안에 read_csv()함수를 이용하여 데이터프레임 로드 \n",
    "    # file_path(../../csv/2017)\n",
    "    # file_name(201701_expense_list.csv)\n",
    "    # file_path + file_name -> ../../csv/2017201701_expense_list.csv\n",
    "    # 경로상 문제 발생 \n",
    "    # file_path + \"/\" + file_name -> ../../csv/2017/201701_expense_list.csv\n",
    "    df = pd.read_csv( file_path + \"/\" + file_name )\n",
    "    # 첫번째 반복 :  df = 201701 데이터프레임 생성\n",
    "    #               concat()이용해서 df_2017과 df를 단순 행 결합\n",
    "    df_2017 = pd.concat( [df_2017, df] , axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70132"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5517"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\n",
    "    pd.read_csv(\"../../csv/2017/201701_expense_list.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019년도 폴더에 있는 파일들의 목록을 모두 로드하여 \n",
    "# 하나의 데이터프레임으로 생성\n",
    "file_path = \"../../csv/2019/\"\n",
    "file_list = os.listdir(file_path)\n",
    "df_2019 = pd.DataFrame()\n",
    "\n",
    "i = 0 \n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        file_name = file_list[i]\n",
    "\n",
    "        df = pd.read_json(file_path + file_name)\n",
    "        df_2019 = pd.concat([df_2019, df], axis=0)\n",
    "        i += 1\n",
    "    except:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74207"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../csv/2020/\"\n",
    "file_list = os.listdir(file_path)\n",
    "\n",
    "df_2020 = pd.DataFrame()\n",
    "\n",
    "for file_name in file_list:\n",
    "    df = pd.read_excel(file_path + file_name)\n",
    "    df_2020 = pd.concat([df_2020, df])\n",
    "# 인덱스 초기화하고 기존 인덱스 제거 \n",
    "df_2020.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob()\n",
    "glob(\"../../csv/2021/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수를 생성 \n",
    "- 매개변수 2개 생성 ( _path, _end )\n",
    "    - _path : 특정 경로\n",
    "    - _end : 기본값(csv), 확장자 선택\n",
    "- _path의 파일 목록을 저장\n",
    "- 빈 데이터프레임 생성\n",
    "- 파일의 목록을 기준으로 반복문 생성\n",
    "    - _end에 따라 read_xxxx() 호출\n",
    "    - 빈 데이터프레임에 read함수를 이용한 데이터프레임을 결합\n",
    "    - 결합될때마다 데이터프레임의 길이를 출력\n",
    "- 결합된 데이터프레임을 되돌려준다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(_path, _end = 'csv'):\n",
    "    # 파일의 목록을 생성 \n",
    "    file_list = os.listdir(_path)\n",
    "    # 빈 데이터프레임 생성 \n",
    "    result = pd.DataFrame()\n",
    "    file_path = _path + '/'\n",
    "    # file_list2 = glob(file_path + \"*.\" + _end)\n",
    "    # case1 특정 파일 목록을 생성하는 방법\n",
    "    # file_list에서 특정 확장자를 가진 파일의 목록을 새로 만든다. \n",
    "    file_list2 = []\n",
    "    for file in file_list:\n",
    "        # file : 파일의 풀네임 ( 이름 + 확장자 )\n",
    "        # 문자열의 마지막이 포함 여부를 나타내는 함수\n",
    "        # if file.endswith(_end):\n",
    "        # 문자열에서 _end의 길이만큼 마지막 문자를 출력해서 비교\n",
    "        # if file[ -len(_end) : ] == _end:\n",
    "        if file.split('.')[-1] == _end:\n",
    "            file_list2.append(file)\n",
    "\n",
    "    \n",
    "\n",
    "    # for file_name in file_list:\n",
    "    for file_name in file_list2:\n",
    "        if _end == \"csv\":\n",
    "            df = pd.read_csv(file_path + file_name)\n",
    "        elif _end == 'json':\n",
    "            df = pd.read_json(file_path + file_name)\n",
    "        elif _end == 'xml':\n",
    "            df = pd.read_xml(file_path + file_name)\n",
    "        # elif _end == 'xlsx' or _end == 'xls':\n",
    "        elif _end in ['xlsx', 'xls']:\n",
    "            df = pd.read_excel(file_path + file_name)\n",
    "        else:\n",
    "            # 함수에서 return의 기능?\n",
    "            # 값을 되돌려준다. \n",
    "            # 함수를 종료\n",
    "            return \"해당 확장자는 사용이 불가능합니다.\"\n",
    "        # 빈데이터프레임에 결합 \n",
    "        result = pd.concat( [result, df] )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../csv/2021\\\\202101_expense_list.xml',\n",
       " '../../csv/2021\\\\202102_expense_list.xml',\n",
       " '../../csv/2021\\\\202103_expense_list.xml',\n",
       " '../../csv/2021\\\\202104_expense_list.xml',\n",
       " '../../csv/2021\\\\202105_expense_list.xml',\n",
       " '../../csv/2021\\\\202106_expense_list.xml',\n",
       " '../../csv/2021\\\\202107_expense_list.xml',\n",
       " '../../csv/2021\\\\202108_expense_list.xml',\n",
       " '../../csv/2021\\\\202109_expense_list.xml',\n",
       " '../../csv/2021\\\\202110_expense_list.xml',\n",
       " '../../csv/2021\\\\202111_expense_list.xml',\n",
       " '../../csv/2021\\\\202112_expense_list.xml']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(\"../../csv/2021/*.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load('../../csv/2021', 'xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문자의 위치를 기준으로 조건식 생성 \n",
    "file_path[-1] == '/'\n",
    "# endswith() 함수를 이용\n",
    "file_path.endswith('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_list = [1,2,3,4]\n",
    "_list.remove(3)\n",
    "_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(_path, _end = 'csv'):\n",
    "    # 빈 데이터프레임 생성 \n",
    "    result = pd.DataFrame()\n",
    "    file_path = _path + '/'\n",
    "    file_list2 = glob(file_path + \"*.\" + _end)\n",
    "\n",
    "    \n",
    "\n",
    "    # for file_name in file_list:\n",
    "    for file_name in file_list2:\n",
    "        if _end == \"csv\":\n",
    "            df = pd.read_csv(file_name)\n",
    "        elif _end == 'json':\n",
    "            df = pd.read_json(file_name)\n",
    "        elif _end == 'xml':\n",
    "            df = pd.read_xml(file_name)\n",
    "        # elif _end == 'xlsx' or _end == 'xls':\n",
    "        elif _end in ['xlsx', 'xls']:\n",
    "            df = pd.read_excel(file_name)\n",
    "        else:\n",
    "            # 함수에서 return의 기능?\n",
    "            # 값을 되돌려준다. \n",
    "            # 함수를 종료\n",
    "            return \"해당 확장자는 사용이 불가능합니다.\"\n",
    "        # 빈데이터프레임에 결합 \n",
    "        result = pd.concat( [result, df] )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load2(_path, _end = 'csv'):\n",
    "    file_list = glob(_path + '/*.' + _end)\n",
    "\n",
    "    # 반복문을 이용해서 전역변수들을 생성\n",
    "    i = 1\n",
    "    for file in file_list:\n",
    "        if _end == 'csv':\n",
    "            globals()[f\"df{i}\"] = pd.read_csv(file)\n",
    "        elif _end == 'json':\n",
    "            globals()[f\"df{i}\"] = pd.read_json(file)\n",
    "        elif _end == 'xml':\n",
    "            globals()[f\"df{i}\"] = pd.read_xml(file)\n",
    "        elif _end in ['xlsx', 'xls']:\n",
    "            globals()[f\"df{i}\"] = pd.read_excel(file)\n",
    "        else:\n",
    "            return \"지원하는 확장자가 아닙니다.\"\n",
    "        print(f\"df{i} 변수가 생성\" )\n",
    "        i += 1\n",
    "    print(\"변수 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 변수가 생성\n",
      "df2 변수가 생성\n",
      "df3 변수가 생성\n",
      "df4 변수가 생성\n",
      "변수 생성 완료\n"
     ]
    }
   ],
   "source": [
    "data_load2(\"../../csv/num_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>campaign_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA1</td>\n",
       "      <td>2_일반</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA2</td>\n",
       "      <td>0_입회비반액할인</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA3</td>\n",
       "      <td>1_입회비무료</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  campaign_id campaign_name\n",
       "0         CA1          2_일반\n",
       "1         CA2     0_입회비반액할인\n",
       "2         CA3       1_입회비무료"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>class_name</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C01</td>\n",
       "      <td>0_종일</td>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C02</td>\n",
       "      <td>1_주간</td>\n",
       "      <td>7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C03</td>\n",
       "      <td>2_야간</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class class_name  price\n",
       "0   C01       0_종일  10500\n",
       "1   C02       1_주간   7500\n",
       "2   C03       2_야간   6000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "      <th>gender</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>is_deleted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OA832399</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>C01</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL270116</td>\n",
       "      <td>XXXXX</td>\n",
       "      <td>C01</td>\n",
       "      <td>M</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OA974876</td>\n",
       "      <td>XXXXX</td>\n",
       "      <td>C01</td>\n",
       "      <td>M</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HD024127</td>\n",
       "      <td>XXXXX</td>\n",
       "      <td>C01</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HD661448</td>\n",
       "      <td>XXXXX</td>\n",
       "      <td>C03</td>\n",
       "      <td>F</td>\n",
       "      <td>2015-05-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>HD676663</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>C01</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-03-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>HD246549</td>\n",
       "      <td>XXXXX</td>\n",
       "      <td>C01</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-03-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4189</th>\n",
       "      <td>GD037007</td>\n",
       "      <td>XXXXX</td>\n",
       "      <td>C03</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-03-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4190</th>\n",
       "      <td>OA953150</td>\n",
       "      <td>XXXXX</td>\n",
       "      <td>C01</td>\n",
       "      <td>M</td>\n",
       "      <td>2019-03-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>IK692635</td>\n",
       "      <td>XXXXX</td>\n",
       "      <td>C02</td>\n",
       "      <td>F</td>\n",
       "      <td>2019-03-15 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4192 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id   name class gender           start_date end_date  \\\n",
       "0       OA832399   XXXX   C01      F  2015-05-01 00:00:00      NaN   \n",
       "1       PL270116  XXXXX   C01      M  2015-05-01 00:00:00      NaN   \n",
       "2       OA974876  XXXXX   C01      M  2015-05-01 00:00:00      NaN   \n",
       "3       HD024127  XXXXX   C01      F  2015-05-01 00:00:00      NaN   \n",
       "4       HD661448  XXXXX   C03      F  2015-05-01 00:00:00      NaN   \n",
       "...          ...    ...   ...    ...                  ...      ...   \n",
       "4187    HD676663   XXXX   C01      M  2019-03-14 00:00:00      NaN   \n",
       "4188    HD246549  XXXXX   C01      F  2019-03-14 00:00:00      NaN   \n",
       "4189    GD037007  XXXXX   C03      M  2019-03-14 00:00:00      NaN   \n",
       "4190    OA953150  XXXXX   C01      M  2019-03-14 00:00:00      NaN   \n",
       "4191    IK692635  XXXXX   C02      F  2019-03-15 00:00:00      NaN   \n",
       "\n",
       "     campaign_id  is_deleted  \n",
       "0            CA1           0  \n",
       "1            CA1           0  \n",
       "2            CA1           0  \n",
       "3            CA1           0  \n",
       "4            CA1           0  \n",
       "...          ...         ...  \n",
       "4187         CA1           0  \n",
       "4188         CA1           0  \n",
       "4189         CA1           0  \n",
       "4190         CA1           0  \n",
       "4191         CA1           0  \n",
       "\n",
       "[4192 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>usedate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L00000049012330</td>\n",
       "      <td>AS009373</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L00000049012331</td>\n",
       "      <td>AS015315</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L00000049012332</td>\n",
       "      <td>AS040841</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L00000049012333</td>\n",
       "      <td>AS046594</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L00000049012334</td>\n",
       "      <td>AS073285</td>\n",
       "      <td>2018-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197423</th>\n",
       "      <td>L00000049209753</td>\n",
       "      <td>TS977703</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197424</th>\n",
       "      <td>L00000049209754</td>\n",
       "      <td>TS979550</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197425</th>\n",
       "      <td>L00000049209755</td>\n",
       "      <td>TS995299</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197426</th>\n",
       "      <td>L00000049209756</td>\n",
       "      <td>TS995853</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197427</th>\n",
       "      <td>L00000049209757</td>\n",
       "      <td>TS999079</td>\n",
       "      <td>2019-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197428 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 log_id customer_id     usedate\n",
       "0       L00000049012330    AS009373  2018-04-01\n",
       "1       L00000049012331    AS015315  2018-04-01\n",
       "2       L00000049012332    AS040841  2018-04-01\n",
       "3       L00000049012333    AS046594  2018-04-01\n",
       "4       L00000049012334    AS073285  2018-04-01\n",
       "...                 ...         ...         ...\n",
       "197423  L00000049209753    TS977703  2019-03-31\n",
       "197424  L00000049209754    TS979550  2019-03-31\n",
       "197425  L00000049209755    TS995299  2019-03-31\n",
       "197426  L00000049209756    TS995853  2019-03-31\n",
       "197427  L00000049209757    TS999079  2019-03-31\n",
       "\n",
       "[197428 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../csv', 'a.csv')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"../csv/a.csv\"\n",
    "os.path.split(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../csv/a', '.csv')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load3(_path):\n",
    "    # 파일의 목록 (모든 확장자)\n",
    "    file_list = glob(_path + \"/*.*\")\n",
    "\n",
    "    for file in file_list:\n",
    "        # file : 경로 + 파일 이름 + 확장자\n",
    "        # print(file)\n",
    "        # 경로와 파일의 풀네임을 나눈다. \n",
    "        file_path, file_name = os.path.split(file)\n",
    "        # print(file_path)\n",
    "        # print(file_name) \n",
    "        # file_name에서 이름과 확장자로 나눠준다. \n",
    "        head, tail = os.path.splitext(file_name)\n",
    "        # print(head)\n",
    "        # print(tail)\n",
    "        # 전역 변수 생성 head 변수에 데이터를 사용 \n",
    "        if tail == '.csv':\n",
    "            globals()[head] = pd.read_csv(file)\n",
    "            print(f\"{head}은 전역변수 생성\")\n",
    "        elif tail == \".tsv\":\n",
    "            globals()[head] = pd.read_csv(file, sep='\\t')\n",
    "            print(f\"{head}은 전역변수 생성\")\n",
    "        elif tail == '.json':\n",
    "            globals()[head] = pd.read_json(file)\n",
    "            print(f\"{head}은 전역변수 생성\")\n",
    "        elif tail == '.xml':\n",
    "            globals()[head] = pd.read_xml(file)\n",
    "            print(f\"{head}은 전역변수 생성\")\n",
    "        elif tail in ['.xlsx', '.xls']:\n",
    "            globals()[head] = pd.read_excel(file)\n",
    "            print(f\"{head}은 전역변수 생성\")\n",
    "        else:\n",
    "            print(f\"{file_name}은 전역변수 생성 실패\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL은 전역변수 생성\n",
      "chipotle은 전역변수 생성\n",
      "Koweps_Codebook은 전역변수 생성\n"
     ]
    }
   ],
   "source": [
    "data_load3(\"./data2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>변수명</th>\n",
       "      <th>설명</th>\n",
       "      <th>내용</th>\n",
       "      <th>범위</th>\n",
       "      <th>모름/무응답</th>\n",
       "      <th>출처 조사설계서</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h10_g3</td>\n",
       "      <td>성별</td>\n",
       "      <td>1.남         2.여</td>\n",
       "      <td>N(1~2)</td>\n",
       "      <td>모름/무응답=9</td>\n",
       "      <td>10차 머지데이터_변수명.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h10_g4</td>\n",
       "      <td>태어난 연도</td>\n",
       "      <td>년</td>\n",
       "      <td>N(1900~2014)</td>\n",
       "      <td>모름/무응답=9999</td>\n",
       "      <td>10차 머지데이터_변수명.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>h10_g10</td>\n",
       "      <td>혼인상태</td>\n",
       "      <td>0.비해당(18세 미만)\\n1.유배우         2.사별         3.이혼...</td>\n",
       "      <td>N(0~6)</td>\n",
       "      <td>모름/무응답=9</td>\n",
       "      <td>10차 머지데이터_변수명.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h10_g11</td>\n",
       "      <td>종교</td>\n",
       "      <td>1.있음                2.없음</td>\n",
       "      <td>N(1~2)</td>\n",
       "      <td>모름/무응답=9</td>\n",
       "      <td>10차 머지데이터_변수명.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>h10_eco9</td>\n",
       "      <td>직종</td>\n",
       "      <td>직종 코드표 참조</td>\n",
       "      <td>N(직종코드 시트참조)</td>\n",
       "      <td>모름/무응답=9999</td>\n",
       "      <td>10차 머지데이터_변수명.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p1002_8aq1</td>\n",
       "      <td>일한달의 월 평균 임금</td>\n",
       "      <td>만원</td>\n",
       "      <td>N(1~9998)</td>\n",
       "      <td>모름/무응답=9999</td>\n",
       "      <td>(2015년 10차 한국복지패널조사) 조사설계서-가구원용(beta1).xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>h10_reg7</td>\n",
       "      <td>7개 권역별 지역구분</td>\n",
       "      <td>1. 서울          2. 수도권(인천/경기)    3. 부산/경남/울산   ...</td>\n",
       "      <td>N(1~7)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2015년 10차 한국복지패널조사) 조사설계서-가구용(beta1).xlsx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          변수명            설명  \\\n",
       "0      h10_g3            성별   \n",
       "1      h10_g4        태어난 연도   \n",
       "2     h10_g10          혼인상태   \n",
       "3     h10_g11            종교   \n",
       "4    h10_eco9            직종   \n",
       "5  p1002_8aq1  일한달의 월 평균 임금   \n",
       "6    h10_reg7   7개 권역별 지역구분   \n",
       "\n",
       "                                                  내용            범위  \\\n",
       "0                                    1.남         2.여        N(1~2)   \n",
       "1                                                  년  N(1900~2014)   \n",
       "2  0.비해당(18세 미만)\\n1.유배우         2.사별         3.이혼...        N(0~6)   \n",
       "3                           1.있음                2.없음        N(1~2)   \n",
       "4                                          직종 코드표 참조  N(직종코드 시트참조)   \n",
       "5                                                 만원     N(1~9998)   \n",
       "6  1. 서울          2. 수도권(인천/경기)    3. 부산/경남/울산   ...        N(1~7)   \n",
       "\n",
       "        모름/무응답                                     출처 조사설계서  \n",
       "0     모름/무응답=9                           10차 머지데이터_변수명.xlsx  \n",
       "1  모름/무응답=9999                           10차 머지데이터_변수명.xlsx  \n",
       "2     모름/무응답=9                           10차 머지데이터_변수명.xlsx  \n",
       "3     모름/무응답=9                           10차 머지데이터_변수명.xlsx  \n",
       "4  모름/무응답=9999                           10차 머지데이터_변수명.xlsx  \n",
       "5  모름/무응답=9999  (2015년 10차 한국복지패널조사) 조사설계서-가구원용(beta1).xlsx  \n",
       "6          NaN   (2015년 10차 한국복지패널조사) 조사설계서-가구용(beta1).xlsx  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Koweps_Codebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
