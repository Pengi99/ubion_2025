{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 웹 크롤링\n",
    "1. 사용할 라이브러리 목록 \n",
    "    - requests\n",
    "        - 웹 통신을 위한 라이브러리 \n",
    "        - 웹서버에 요청을 보내고 응답을 받아오는 라이브러리 \n",
    "        - get( 웹주소, params = data, headers = data )\n",
    "    - bs4\n",
    "        - BeautifulSoup class를 사용\n",
    "        - html문서형 데이터를 parsing을 하여 데이터를 쉽게 추출 할 수 있도록 도와주는 기능\n",
    "        - html의 TAG를 기준으로 데이터를 추출 \n",
    "        - 웹의 구조를 어느정도 인지하고 사용하면 쉽게 접근이 가능\n",
    "        - Parser를 활용해서 python에서 접근이 쉽게 객체 형태로 제공\n",
    "    - selenium \n",
    "        - 웹 어플리케이션를 테스트를 하기 위한 라이브러리 \n",
    "        - 웹 브라우져를 python의 code를 이용해서 제어 \n",
    "        - Chrome의 버전이 구버전이거나 selenium이 구 버전인 경우에는 별도의 소프트웨어를 설치 \n",
    "        - 특정 동적인 웹 페이지에서 데이터를 가지고 올때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.naver.com\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(html_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data.find('네이버')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data[378:410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing 작업 : 데이터의 타입을 변경 ( 내가 사용하기 편한 형태로 변경 )\n",
    "soup = bs(html_data, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BeautifulSoup 내장함수\n",
    "    - soup.태그명 -> html 문서에서 해당 태그명의 첫번째 정보를 출력\n",
    "    - soup.태그명.string -> 첫번째 정보에서 contents부분의 문자를 출력\n",
    "    - soup.태그명['속성명'] : 첫번째 태그의 정보에서 속성의 값을 출력\n",
    "    - find(태그명)\n",
    "        - html 문서에서 해당 태그명의 첫번째 정보를 출력 \n",
    "        - find(속성명 = 속성값) : 태그들 중 해당 속성을 가지고 속성값을 가신 태그의 첫번째 정보를 출력\n",
    "        - 반환되는 값의 type은 TAG\n",
    "    - find_all(태그명)\n",
    "        - html 문서에서 해당 태그명의 모든 정보를 출력 \n",
    "        - limit 매개변수 : 태그 정보의 개수를 설정\n",
    "        - 반환되는 값의 type이 TAG_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup에서 a태그의 정보를 출력 \n",
    "print(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.a.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.find('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.find_all('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_list = soup.find_all('a', limit=3)\n",
    "a_list = soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list[1].find('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_list에 있는 모든 원소들에 contents만 추출하여 새로운 리스트 생성\n",
    "\n",
    "# case1 반복문 이용 \n",
    "contents_list = []\n",
    "\n",
    "# 반복문 생성 \n",
    "for a_tag in a_list:\n",
    "    # a_tag -> a_list에 있는 각 원소(TAG)들이 한번씩 대입\n",
    "    contents_list.append( a_tag.string )\n",
    "\n",
    "contents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while문\n",
    "contents_list2 = []\n",
    "\n",
    "# 초기값 \n",
    "i = 0\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        contents_list2.append(a_list[i].get_text())\n",
    "        i += 1\n",
    "    except:\n",
    "        break\n",
    "contents_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case2 map함수를 이용\n",
    "list(\n",
    "    map(\n",
    "        lambda x : x.string, \n",
    "        a_list\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string(x):\n",
    "    # x에는 TAG 데이터 대입 \n",
    "    result = x.get_text()\n",
    "    return result\n",
    "\n",
    "list(\n",
    "    map(\n",
    "        get_string, \n",
    "        a_list\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 파이낸스 \n",
    "# 1. 요청을 보내고 응답을 받는다. \n",
    "url  = \"https://finance.naver.com/\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 응답 메시지에서 문자로 출력 변수에 저장 \n",
    "html_data = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4에 BeautifulSoup을 이용하여 데이터를 파싱 (class 생성성)\n",
    "soup = bs(html_data, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요뉴스의 헤드라인 텍스트를 출력 \n",
    "# div TAG들 중에 class 속성의 값이 \"section_strategy\"인 태그를 찾는다. \n",
    "\n",
    "len(soup.find_all('div', attrs={\n",
    "    'class' : 'section_strategy'\n",
    "}))\n",
    "# find_all로 태그를 검색하고 길이를 확인하니 1\n",
    "# html 문서에서 해당 태그는 1개 -> find()함수를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_data = soup.find('div', attrs={\n",
    "    'class' : 'section_strategy'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# div_data에서 li태그의 정보를 모두 출력\n",
    "li_list = div_data.find_all('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li_list에서 텍스트 추출하여 새로운 리스트로 생성\n",
    "news_data = list(\n",
    "    map(\n",
    "        lambda x : x.get_text().strip(), \n",
    "        li_list\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html 문서에서 div중 class가 krx_group_type이 태그 모두를 찾는다. \n",
    "divs_list = soup.find_all('div', attrs={\n",
    "    'class' : 'krx_group_type'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(divs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data1 = divs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table 태그의 데이터를 가지고 와서 데이터프레임으로 변경 \n",
    "# columns의 값을 따로 추출 (1차원 데이터)\n",
    "# thead 태그 안에 th 태그들의 텍스트 추출\n",
    "thead_data = table_data1.find('thead')\n",
    "th_list = thead_data.find_all('th')\n",
    "# th_list에 있는 문자를 각각 추출하여 리스트로 생성\n",
    "cols = list(\n",
    "    map(\n",
    "        lambda x : x.get_text(), \n",
    "        th_list\n",
    "    )\n",
    ")\n",
    "cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values의 값을 따로 추출 (2차원 데이터)\n",
    "# tbody태그의 정보를 추출 \n",
    "tbody_data = table_data1.find('tbody')\n",
    "# tbody_data에서 모든 tr태그를 찾는다\n",
    "tr_list = tbody_data.find_all('tr')\n",
    "# tr_list에서 우선 첫번째 데이터를 추출\n",
    "tr_data = tr_list[0]\n",
    "# tr_data에서 th태그와 td태그를 모두 찾는다. \n",
    "val_list = tr_data.find_all( ['th', 'td'] )\n",
    "# val_list에서 텍스트를 출력하여 새로운 리스트를 생성\n",
    "first_values = list(\n",
    "    map(\n",
    "        lambda x : x.get_text().strip(), \n",
    "        val_list\n",
    "    )\n",
    ")\n",
    "first_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for tr_data in tr_list:\n",
    "    # tr_data에서 th태그와 td태그를 모두 찾는다. \n",
    "    val_list = tr_data.find_all( ['th', 'td'] )\n",
    "    value = []\n",
    "    for val in val_list:\n",
    "        # val -> <th>..., <td>.... TAG데이터\n",
    "        # val에서 텍스트를 추출하여 value에 추가\n",
    "        value.append( val.get_text().strip() )\n",
    "    # 두번째 반복문이 종료한 뒤 value를 values에 추가 \n",
    "    values.append(value)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['KODEX 200선물인버스2X', '2,235', '하락 70', '-3.04%'],\n",
       " ['삼성중공업', '15,270', '상승 1,050', '+7.38%'],\n",
       " ['티에스넥스젠', '247', '상승 41', '+19.90%'],\n",
       " ['우듬지팜', '1,664', '상승 193', '+13.12%'],\n",
       " ['KODEX 레버리지', '15,795', '상승 445', '+2.90%'],\n",
       " ['에스엠씨지', '3,855', '상승 710', '+22.58%'],\n",
       " ['KODEX 코스닥150선물인버스', '3,820', '하락 60', '-1.55%'],\n",
       " ['KODEX 인버스', '4,490', '하락 70', '-1.54%'],\n",
       " ['KODEX 코스닥150레버리지', '7,740', '상승 215', '+2.86%'],\n",
       " ['동양철관', '927', '하락 14', '-1.49%'],\n",
       " ['아이씨티케이', '12,890', '상승 1,470', '+12.87%'],\n",
       " ['클리노믹스', '592', '상승 136', '+29.82%'],\n",
       " ['클로봇', '22,550', '상승 550', '+2.50%'],\n",
       " ['피아이이', '12,190', '상승 370', '+3.13%'],\n",
       " ['삼성전자', '54,700', '상승 1,100', '+2.05%']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func_1(tr_data):\n",
    "    # tr_data 매개변수에 대입이 될 데이터? -> tr_list에 각 원소들이 대입\n",
    "    val_list = tr_data.find_all( ['th', 'td'] )\n",
    "    result = list(\n",
    "        map(\n",
    "            lambda val : val.get_text().strip(), \n",
    "            val_list\n",
    "        )\n",
    "    )\n",
    "    return result\n",
    "\n",
    "values2 = list(\n",
    "    map(\n",
    "        func_1, \n",
    "        tr_list\n",
    "    )\n",
    ")\n",
    "values2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
