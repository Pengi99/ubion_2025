{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 스케일링\n",
    "- 대부분 분석알고리즘은 컬럼 간 데이터의 범위가 크게 차이나는 경우에는 작동이 잘 되지 않는다. \n",
    "- 값의 범위가 작은 컬럼에 비해서 값의 범위가 큰 컬럼이 타겟 범수를 예측하는데 큰 영향을 준다. \n",
    "- 스케일링 작업은 모든 컬럼의 값의 범위를 같게 만들어주는 작업\n",
    "- 스케일링 순서 \n",
    "    - 데이터 스케일링의 주의할 점 train데이터와 test데이터를 같은 scaler 객체로 스케일링 해야한다. \n",
    "    1. Scaler 선택 및 import \n",
    "    2. Scaler 객체 생성 (Class)\n",
    "    3. train 데이터 분포를 저장\n",
    "    4. train 데이터 스케일링 \n",
    "    5. test 데이터 스케일링\n",
    "    6. 원래의 데이터로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaler\n",
    "- 표준화 방식으로 기본 스케일링으로 컬럼들을 평균이 0, 분산이 1인 정규분포로 스케일링\n",
    "- 최솟값과 최댓값의 크기를 제한하지 않아 이상치에 민감하기 때문에 이상치에 대한 확인 및 정제를 한 후 사용 \n",
    "- 회귀보다는 분류분석에서 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "iris = pd.DataFrame(iris_data['data'], columns = iris_data['feature_names'])\n",
    "iris['Class'] = iris_data['target']\n",
    "\n",
    "iris['Class'] = iris['Class'].map(\n",
    "    {\n",
    "        0 : 'Setosa', \n",
    "        1 : 'Versicolour', \n",
    "        2 : 'Virginaca'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "c:\\Users\\moons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    iris.drop('Class', axis=1), \n",
    "    iris['Class'], \n",
    "    test_size= 0.3, \n",
    "    random_state= 1000, \n",
    "    stratify= iris['Class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler 선택 : Standard\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler 객체 생성 -> Class 생성\n",
    "StdScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 데이터의 분포를 저장\n",
    "StdScaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 데이터 스케일링\n",
    "X_train_sc = StdScaler.transform(X_train)\n",
    "# test 데이터 스케일링 \n",
    "X_test_sc = StdScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train min : -1.8148176152734814, \n",
      "      max : 2.9247930249692984, \n",
      "      mean : -1.3005469717037547e-15, \n",
      "      std : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Standaer Scaler는 평균이 0 분산 1\n",
    "print(f\"\"\"X_Train min : {X_train_sc.min()}, \n",
    "      max : {X_train_sc.max()}, \n",
    "      mean : {X_train_sc.mean()}, \n",
    "      std : {X_train_sc.std()}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train min : -2.3777094375649708, \n",
      "      max : 2.257400415227029, \n",
      "      mean : 0.007383725095262762, \n",
      "      std : 0.9554677587702913\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"X_Train min : {X_test_sc.min()}, \n",
    "      max : {X_test_sc.max()}, \n",
    "      mean : {X_test_sc.mean()}, \n",
    "      std : {X_test_sc.std()}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
